---
title: Requests & 뷰티풀수프 파싱 기초
date: 2022-06-24 13:55:00 +0900
tags: [프로그래밍, 파이썬, 웹크롤링]
---

## 개요

웹크롤링을 자주 하는 편이 아니지만, 그럼에도 이따금씩 필요한 일이 생긴다.

문제는 몇 개월에 한 번씩 하려다 보니 매번 강좌를 찾아보고 있다는 사실. 이쯤 되니 꼭 필요한 것만 모아 정리해두는 게 낫겠다 싶었다.

그런 이유로, 거두절미하고 바로 본론으로 들어가보자.

---

## Requests

파이썬 내장 웹 통신 라이브러리인 `urllib`보다 10만 배 편하다. 그냥 이거 쓰자.

### 설치 명령어

```powershell
pip install requests
```

### 불러오기

```python
import requests
```

### get 요청

```python
url = 'https://www.google.com/'
res = requests.get(url)
```

### 쿼리스트링

```python
# 방법 1
url = 'https://www.google.com/search?q=Gabriel+Dropout'
res = requests.get(url)

# 방법 2
url = 'https://www.google.com/search'
payload = {'q':'Gabriel+Dropout'}
res = requests.get(url, params=payload)
```

### post 요청 + 헤더 + 쿠키

```python
url = '사이트 주소'
data = {'key':'value'}
headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64)'}
cookies = {'session_id':'1q2w3e4r'}
res = requests.post(url, data, headers=headers, cookies=cookies)
```

### 세션 유지

```python
url = '사이트 주소'
s = requests.Session()  # 세션 생성

res = s.get(url)
cookies = res.cookies  # 쿠키 저장
data = {'key':'value'}

res = requests.post(url, data, headers=headers, cookies=cookies)  # 쿠키 재전송

s.close()

```

### 응답 정보

```python
res.request  # 리퀘스트 정보
res.headers  # 헤더 정보
res.status_code  # 상태 코드
res.text  # html데이터를 문자열로 반환
res.json()  # json데이터를 딕셔너리로 바로 로드
```

---

## BeautifulSoup

보다 자세한 정보는 다음 링크를 참조하자.

[공식 레퍼런스](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

### 설치 명령어

```powershell
pip install beautifulsoup4
```

### 불러오기

```python
from bs4 import BeautifulSoup
```

### 파싱

```python
soup = BeautifulSoup(res.text, 'html.parser')
```

### 조건을 만족하는 첫 번째 element

```python
soup.find('a')
soup.find('ul', id='link3', class_='clearfix')
soup.find('a', href='www.blabla.com/')
soup.a  # 축약형
```

### 조건을 만족하는 모든 element

```python
soup.find_all('a')
soup.find_all(id=True)  # id 속성을 가진 element
soup.find_all(attrs={"data": "value"})  # 딕셔너리 형태로 넘기기
soup('a')  # 축약형
```

### 직계 자손 반환

```python
tag.find_all(revursive=False)  # 오직 태그만 리스트로 반환
tag.contents  # 리스트로 반환(태그가 아닌 NavigableString 객체 등이 함께 있을 수도 있다)
tag.children  # 반복자로 반환
```

### 부모 반환

```
tag.parent
```

### 형제 반환

```python
tag.next_sibling
tag.previous_sibling
```

### 태그 정보 반환

```python
tag.name
tag['class']
tag['id']
tag.name
```

---

## 여담

추가하거나 수정 사항이 있을 수도 있겠다.

다음부터는 저것들 때문에 google 위를 떠돌아 다니지 않아도...되겠지?
